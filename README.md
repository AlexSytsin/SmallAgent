# AI Research Agent

Этот проект представляет собой автономного AI-агента для проведения исследований на заданную тему. Агент использует FastAPI для веб-интерфейса и LangGraph для оркестрации сложного рабочего процесса, включающего несколько моделей LLM (через Groq API) и поиск в интернете (через Google Custom Search API).

## Особенности

- **Автономное исследование**: Просто задайте тему, и агент сам сформулирует поисковые запросы, найдет информацию, извлечет ключевые факты и напишет аналитический отчет.
- **Многоагентный подход**: Используется цепочка из трех специализированных узлов (Searcher, Summarizer, Reasoner), каждый из которых может использовать свою LLM.
- **Цитирование источников**: Финальный отчет автоматически включает ссылки в формате Markdown на источники, из которых были взяты факты.
- **Веб-интерфейс**: Простой и понятный интерфейс для взаимодействия с агентом.
- **Готовность к развертыванию**: Проект легко упаковывается в Docker для быстрой и изолированной установки.

## Как это работает

Рабочий процесс построен на графе состояний (LangGraph) и состоит из трех основных узлов:

1.  **Searcher (Искатель)**:
    - Получает на вход тему.
    - Использует LLM для генерации 3 релевантных поисковых запросов.
    - Выполняет поиск в Google по этим запросам.
    - Скачивает содержимое найденных страниц и очищает его от "мусора".
    - Передает уникальные источники данных следующему узлу.

2.  **Summarizer (Суммаризатор)**:
    - Принимает очищенные источники.
    - Анализирует текст и извлекает из него 3-5 ключевых, строго релевантных теме фактов.
    - Для каждого факта сохраняет URL-источник и дату публикации (если находит).
    - Передает список структурированных фактов дальше.

3.  **Reasoner (Аналитик)**:
    - Получает список фактов.
    - Использует самую мощную LLM для написания глубокого аналитического вывода.
    - Синтезирует информацию, а не просто перечисляет факты, и **обязательно цитирует источники** с датами в формате Markdown.
    - Генерирует итоговый отчет.

## Технологический стек

- **Бэкенд**: FastAPI
- **Оркестрация AI**: LangChain (LangGraph)
- **LLM Провайдер**: Groq API (для Llama 3.1, Llama 4, Llama 3.3)
- **Поиск**: Google Custom Search API
- **Контейнеризация**: Docker, Docker Compose
- **Зависимости**: Pydantic, Uvicorn, и другие (см. `requirements.txt`)

---

## Запуск проекта

Есть два способа запустить проект: локально с помощью виртуального окружения или с помощью Docker.

### 1. Локальный запуск

**Шаг 1: Клонирование репозитория**
```bash
git clone https://github.com/AlexSytsin/SmallAgent.git
```

**Шаг 2: Настройка переменных окружения**

Для работы приложения необходимы API-ключи. Создайте файл `.env` в корне проекта, скопировав `.env.example`.

```bash
cp .env.example .env
```

Теперь откройте файл `.env` и вставьте ваши ключи:

```env
# .env

# Ключ от Groq API (https://console.groq.com/keys)
GROQ_API_KEY="gsk_..."

# Ключи от Google Custom Search API
# 1. API Key (https://console.cloud.google.com/apis/credentials)
GOOGLE_API_KEY="AIza..."
# 2. Search Engine ID (CX) (https://programmablesearchengine.google.com/)
GOOGLE_CX="..."
```

**Шаг 3: Установка зависимостей**

Рекомендуется использовать uv.

```bash
# Создание виртуального окружения
uv venv

# Установка зависимостей
uv pip install -r requirements.txt
```

**Шаг 4: Запуск FastAPI приложения**

```bash
uvicorn main:app --reload
```

Приложение будет доступно по адресу [http://127.0.0.1:8000](http://127.0.0.1:8000).

### 2. Запуск с помощью Docker (Рекомендуемый)

**Шаг 1 и 2**: Выполните шаги 1 и 2 из локального запуска (клонирование и настройка `.env` файла).

**Шаг 3: Сборка и запуск контейнера**

Убедитесь, что у вас установлен Docker и Docker Compose.

```bash
docker-compose up --build
```

Эта команда автоматически соберет образ и запустит контейнер. Приложение будет доступно по адресу [http://127.0.0.1:8000](http://127.0.0.1:8000).

Чтобы остановить приложение, нажмите `Ctrl+C`.

## Использование API

После запуска вы можете открыть веб-интерфейс по адресу [http://127.0.0.1:8000](http://127.0.0.1:8000) или отправить POST-запрос на эндпоинт `/analyze`.

**Пример `curl` запроса:**

```bash
curl -X POST "http://127.0.0.1:8000/analyze" \
-H "Content-Type: application/json" \
-d '{"topic": "будущее искусственного интеллекта в медицине"}'
```

## Структура проекта

```
├── graph/        # Логика LangGraph (узлы, состояние)
├── services/     # Внешние сервисы (LLM, веб-поиск)
├── static/       # Фронтенд (HTML, CSS, JS)
├── .env          # Секретные ключи (не попадает в Git)
├── .env.example  # Шаблон для .env
├── config.py     # Конфигурация приложения
├── main.py       # Точка входа FastAPI
├── schemas.py    # Структуры данных
├── Dockerfile    # Инструкции для сборки Docker-образа
└── docker-compose.yml # Файл для запуска через Docker Compose
```
